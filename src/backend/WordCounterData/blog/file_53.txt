5113341 <h> Saturday, 17 November 2012 <h> Benford 's Law with real world data. <p> If one has a large enough real life source of data( such as the size of files in the file system) and look at the distribution of the first digit of these values then one will find something that at first glance is rather surprising. The leading digit 1 appears about 30% of the time and as the digits increase to 9 their frequency drops until we reach 9, which only appears about 5% of the time. This seemingly curious frequency distribution is commonly known as Benford 's law or the first digit law. <p> The probability P of digit d can be expresses as follows : <p> P(d) = log 10( 1 + 1 / d) <p>.. where d is any integer value 1 to 9 inclusive. So for each leading digit in the data, the distribution works out to be about : <p> Digit <p> Probability <p> 1 <p> 0.301 <p> 2 <p> 0.176 <p> 3 <p> 0.125 <p> 4 <p> 0.097 <p> 5 <p> 0.079 <p> 6 <p> 0.067 @ @ @ @ @ @ @ @ @ @ <p> 0.046 <p> But how does this hold up with some " real world " data? Can it really be true? Well, for my first experiment, I analysed the leading digit of all the source files in the current Linux source tree and compared that to Benford 's Law : <p> So, this is convincing enough. How about something more exotic? For my second experiment I counted up the number of comments in each file that start with /* in just the C source files in the Linux source tree and again looked at the distribution of the leading digits. I was hazarding a guess that there are a reasonable amount of comments in each file( knowing the way some code is commented this may be pushing my luck). Anyhow, the data generated also produces a distribution that obeys Benford 's Law too : <p> Well, that certainly shows that Kernel developers are sprinkling enough comments in the Kernel source to be statistically meaningful. If the comments themselves are meaningful is another matter... <p> How @ @ @ @ @ @ @ @ @ @ length of every executable in /usr/bin and plotted the distribution of the leading digits from this data : <p>.. this data set has far less files to analyse, so the distribution deviates a little, but the trend is still rather good. <p> As mentioned earlier, one has to have a large set of data for this too work well. Interesting this may be, but what kind of practical use is it? It can be applied to accountancy - if one has a large enough set of data in the accounts and the leading digits of the data do not fit Benford 's Law then maybe one should suspect that somebody has been fiddling the books. Humans are rather poor at making up lots of " random " values that do n't skew Benford 's Law. <p> One more interesting fact is that it applies even if one rescales the data. For example, if you are looking at accounts in terms of sterling and covert it into US dollars or Albanian Lek the rescaled data still obeys Benford 's @ @ @ @ @ @ @ @ @ @ analyse the size of files in bytes but instead used size in 512 byte blocks it still would produce a leading digit distribution that obeyed Benford 's Law. Nice. <p> How can we apply this in computing? Perhaps we could use it to detect tampering with the sizes of a large set of files. Who knows? I am sure somebody can think of a useful way to 
